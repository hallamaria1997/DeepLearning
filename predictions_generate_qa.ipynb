{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8CO1camtnDy"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets==2.5.1\n",
        "\n",
        "!pip install -q apache_beam==2.42.0\n",
        "#mwparserfromhell\n",
        "\n",
        "!pip install -q farm-haystack -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "!pip install -q wikipedia==1.4.0"
      ],
      "id": "V8CO1camtnDy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "156432dc"
      },
      "source": [
        "### Imports"
      ],
      "id": "156432dc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6c61ce6d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from pprint import pprint\n",
        "import wikipedia as wiki\n",
        "import re"
      ],
      "id": "6c61ce6d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfbc345a"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from datasets import load_dataset "
      ],
      "id": "cfbc345a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvGD-jLqtrBk"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "TvGD-jLqtrBk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb5674a4"
      },
      "source": [
        "### Evaluation dataset"
      ],
      "id": "eb5674a4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d662492",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# evaluation data set 1: covid qa deepset, scientific annotated data used to train deepset/roberta-base-squad2-covid\n",
        "d_covid = load_dataset('covid_qa_deepset')\n",
        "QA_covid = d_covid.data['train'].to_pandas()\n",
        "dataQA = {'question': QA_covid['question'][:100],\n",
        "          'answer':[d.get('text')[0] for d in QA_covid[:100].answers],\n",
        "          'wrong_answer': [''] * 100} \n",
        "qa_dataset = pd.DataFrame(dataQA)\n",
        "\n",
        "# evaluation data set 2: qovid qa dataset created using news platforms around the world\n",
        "#qa_dataset = pd.read_csv('/content/drive/MyDrive/DeepLearning/news.csv')\n",
        "#qa_dataset = qa_dataset[['question', 'answer', 'wrong_answer']]\n",
        "#qa_dataset['question'] = 'Covid 19, '+ qa_dataset['question'].astype(str)\n",
        "#qa_dataset.head(3)"
      ],
      "id": "7d662492"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umOB2SzUgFS6"
      },
      "outputs": [],
      "source": [
        "qa_dataset"
      ],
      "id": "umOB2SzUgFS6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ead6bbe1"
      },
      "source": [
        "### Elasticsearch Server"
      ],
      "id": "ead6bbe1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45bf410b"
      },
      "source": [
        "```bash\n",
        "docker pull docker.elastic.co/elasticsearch/elasticsearch:7.9.2\n",
        "\n",
        "docker run -d -p 9200:9200 -e \"discovery.type=single-node\" elasticsearch:7.9.2\n",
        "\n",
        "```"
      ],
      "id": "45bf410b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmdEDw2VuAtq"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.2-linux-x86_64.tar.gz -q\n",
        "tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz\n",
        "chown -R daemon:daemon elasticsearch-7.9.2"
      ],
      "id": "QmdEDw2VuAtq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vp0AYIkPuB7x"
      },
      "outputs": [],
      "source": [
        "%%bash --bg\n",
        "\n",
        "sudo -u daemon -- elasticsearch-7.9.2/bin/elasticsearch"
      ],
      "id": "Vp0AYIkPuB7x"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMhjvfmpuDRg"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "time.sleep(30)"
      ],
      "id": "LMhjvfmpuDRg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aebc075"
      },
      "source": [
        "### Reader imports"
      ],
      "id": "3aebc075"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "add6e734"
      },
      "outputs": [],
      "source": [
        "# just to display the different retrievers available\n",
        "from haystack.nodes import (\n",
        "    BM25Retriever,\n",
        "    TfidfRetriever,\n",
        "    DensePassageRetriever,\n",
        "    FARMReader,\n",
        "    RAGenerator,\n",
        "    BaseComponent,\n",
        "    JoinDocuments,\n",
        ")\n",
        "\n",
        "from haystack.pipelines import (\n",
        "    ExtractiveQAPipeline, \n",
        "    DocumentSearchPipeline, \n",
        "    GenerativeQAPipeline\n",
        ")\n",
        "\n",
        "from haystack.nodes import FARMReader\n",
        "\n",
        "from haystack.utils import print_answers"
      ],
      "id": "add6e734"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8816fdd3"
      },
      "source": [
        "# Definition: MODEL, GPU, TOP_K, READER"
      ],
      "id": "8816fdd3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eebd14cc"
      },
      "outputs": [],
      "source": [
        "# CHANGE MODEL NAME FOR DIFFERENT MODELs\n",
        "# squad 2 model\n",
        "model = \"deepset/roberta-base-squad2\"\n",
        "\n",
        "# squad 2 model trained on covid 19 data\n",
        "# model = \"deepset/roberta-base-squad2-covid\"\n",
        "\n",
        "\n",
        "use_gpu = True\n",
        "\n",
        "top_k_retriever = 10\n",
        "top_k_reader = 5\n",
        "\n",
        "\n",
        "reader = FARMReader(\n",
        "    model_name_or_path=model, #\"deepset/roberta-base-squad2\"\n",
        "    use_gpu=use_gpu\n",
        ")"
      ],
      "id": "eebd14cc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e63cfedb"
      },
      "source": [
        "# Covid "
      ],
      "id": "e63cfedb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0f6b7ef"
      },
      "source": [
        "### Context: COVID-19 Dataset [Link here](https://github.com/deepset-ai/COVID-QA)"
      ],
      "id": "f0f6b7ef"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98a049d2"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/DeepLearning/COVID-QA.json') as jsonfile:\n",
        "    data = json.load(jsonfile)\n",
        "\n",
        "# create the dataframe that holds our data\n",
        "df_covid = pd.DataFrame()\n",
        "for i in range(len(data['data'])):\n",
        "    q = pd.json_normalize(data['data'][i]['paragraphs'][0]['qas'])\n",
        "    contxt = data['data'][i]['paragraphs'][0]['context']\n",
        "    d_id = data['data'][i]['paragraphs'][0]['document_id']\n",
        "    q['context'] = contxt\n",
        "    q['document_id'] = d_id\n",
        "    df_covid = pd.concat([df_covid, q])\n",
        "    \n",
        "df_covid.reset_index(drop=True, inplace=True)\n",
        "df_covid.head(3)"
      ],
      "id": "98a049d2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb3b47b5"
      },
      "outputs": [],
      "source": [
        "df_covid['context_cleaned'] = df_covid.context.apply(\n",
        "    lambda x: re.sub(r'https?:\\/\\/.*?[\\s+]|\\n|[^a-zA-z0-9.]', ' ', x)\n",
        ")"
      ],
      "id": "fb3b47b5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aa0680a"
      },
      "source": [
        "### Document Store"
      ],
      "id": "8aa0680a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sH3PpJX4Rgc"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.2-linux-x86_64.tar.gz -q\n",
        "tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz\n",
        "chown -R daemon:daemon elasticsearch-7.9.2"
      ],
      "id": "5sH3PpJX4Rgc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khHIreAw4Rge"
      },
      "outputs": [],
      "source": [
        "%%bash --bg\n",
        "\n",
        "sudo -u daemon -- elasticsearch-7.9.2/bin/elasticsearch"
      ],
      "id": "khHIreAw4Rge"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXCoafAj4Rge"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "time.sleep(30)"
      ],
      "id": "LXCoafAj4Rge"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26905fb5"
      },
      "outputs": [],
      "source": [
        "documents_lst_covid = df_covid.to_dict(orient='records')"
      ],
      "id": "26905fb5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "520b893d",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# the way document_store wants data formatted\n",
        "dicts_covid = [\n",
        "    {\n",
        "        'content' : str(elm['context']),\n",
        "        'meta' : {\n",
        "            'name' : str(elm['question'])\n",
        "        }\n",
        "    } \n",
        "    for elm in tqdm(documents_lst_covid)\n",
        "]"
      ],
      "id": "520b893d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef236394"
      },
      "source": [
        "Write to document store"
      ],
      "id": "ef236394"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94ca0967"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from haystack.document_stores import ElasticsearchDocumentStore\n",
        "document_store_covid = ElasticsearchDocumentStore(\n",
        "    port=9200\n",
        ")\n",
        "document_store_covid.delete_documents()\n",
        "document_store_covid.write_documents(\n",
        "    documents=dicts_covid\n",
        ")"
      ],
      "id": "94ca0967"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b54e9620"
      },
      "source": [
        "### Retrieving answers"
      ],
      "id": "b54e9620"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "186523bd"
      },
      "source": [
        "#### BM25"
      ],
      "id": "186523bd"
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "E7DOoZ3qlPCY"
      },
      "id": "E7DOoZ3qlPCY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dabea22"
      },
      "outputs": [],
      "source": [
        "retriever = BM25Retriever(document_store=document_store_covid)\n",
        "\n",
        "reader = FARMReader(\n",
        "    model_name_or_path=model, #\"deepset/roberta-base-squad2\"\n",
        "    use_gpu=use_gpu\n",
        ")\n",
        "\n",
        "pipe_covid = ExtractiveQAPipeline(reader, retriever)\n",
        "\n",
        "df_res_covid_bm25  = qa_dataset.copy()\n",
        "\n",
        "# prepare columns for answers\n",
        "df_res_covid_bm25['predictions_covid_context_bm25'] = [list() for x in range(len(df_res_covid_bm25.index))]\n",
        "\n",
        "for q_i in tqdm(range(len(qa_dataset.question.tolist()))):\n",
        "\n",
        "    print('question : ', qa_dataset.question[q_i])\n",
        "\n",
        "    try:\n",
        "        # covid dataset context prediction\n",
        "        prediction_covid = pipe_covid.run(\n",
        "            query=qa_dataset.question[q_i],\n",
        "            params={\n",
        "                \"Retriever\" : {\"top_k\": top_k_retriever},\n",
        "                \"Reader\": {\"top_k\": top_k_reader}\n",
        "            }\n",
        "        )\n",
        "\n",
        "        df_res_covid_bm25.loc[q_i, 'predictions_covid_context_bm25'].append(\n",
        "            [prediction_covid['answers'][k].answer for k in range(len(prediction_covid['answers']))]\n",
        "        )\n",
        "    except:\n",
        "        df_res_covid_bm25.loc[q_i, 'predictions_covid_context_bm25'].append([])\n",
        "\n",
        "    \n",
        "df_res_covid_bm25.to_csv('/content/drive/MyDrive/DeepLearning/df_res_covid_bm25_org_data.csv', index=False)"
      ],
      "id": "6dabea22"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPFfpo9T5gvJ"
      },
      "source": [
        "#### RE-INITIALISE ELASTICSEARCH"
      ],
      "id": "FPFfpo9T5gvJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFkv0KnX7ey-"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.2-linux-x86_64.tar.gz -q\n",
        "tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz\n",
        "chown -R daemon:daemon elasticsearch-7.9.2"
      ],
      "id": "FFkv0KnX7ey-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ffcvat6f7ey-"
      },
      "outputs": [],
      "source": [
        "%%bash --bg\n",
        "\n",
        "sudo -u daemon -- elasticsearch-7.9.2/bin/elasticsearch"
      ],
      "id": "Ffcvat6f7ey-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRyc8fyb7ey_"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "time.sleep(30)"
      ],
      "id": "dRyc8fyb7ey_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K65RwKWB7bmt"
      },
      "source": [
        "Write to document store"
      ],
      "id": "K65RwKWB7bmt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sOnvxjg7bmu"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from haystack.document_stores import ElasticsearchDocumentStore\n",
        "document_store_covid = ElasticsearchDocumentStore(\n",
        "    port=9200\n",
        ")\n",
        "document_store_covid.delete_documents()\n",
        "document_store_covid.write_documents(\n",
        "    documents=dicts_covid\n",
        ")"
      ],
      "id": "7sOnvxjg7bmu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc835355"
      },
      "source": [
        "#### TF IDF"
      ],
      "id": "bc835355"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6acd905e"
      },
      "outputs": [],
      "source": [
        "retriever_tfidf = TfidfRetriever(document_store=document_store_covid)\n",
        "\n",
        "reader = FARMReader(\n",
        "    model_name_or_path=model, #\"deepset/roberta-base-squad2\"\n",
        "    use_gpu=use_gpu\n",
        ")\n",
        "\n",
        "pipe_covid_tfidf = ExtractiveQAPipeline(reader, retriever_tfidf)\n",
        "\n",
        "df_res_covid_tfidf = qa_dataset.copy()\n",
        "\n",
        "# prepare columns for answers\n",
        "df_res_covid_tfidf['predictions_covid_context_tfidf'] = [list() for x in range(len(df_res_covid_tfidf.index))]\n",
        "\n",
        "for q_i in tqdm(range(len(qa_dataset.question.tolist()))):\n",
        "\n",
        "    print('question : ', qa_dataset.question[q_i])\n",
        "\n",
        "    try:\n",
        "        # covid dataset context prediction\n",
        "        prediction_covid = pipe_covid_tfidf.run(\n",
        "            query=qa_dataset.question[q_i],\n",
        "            params={\n",
        "                \"Retriever\" : {\"top_k\": top_k_retriever},\n",
        "                \"Reader\": {\"top_k\": top_k_reader}\n",
        "            }\n",
        "        )\n",
        "\n",
        "        df_res_covid_tfidf.loc[q_i, 'predictions_covid_context_tfidf'].append(\n",
        "            [prediction_covid['answers'][k].answer for k in range(len(prediction_covid['answers']))]\n",
        "        )\n",
        "    except:\n",
        "        df_res_covid_tfidf.loc[q_i, 'predictions_covid_context_tfidf'].append([])\n",
        "\n",
        "\n",
        "df_res_covid_tfidf.to_csv('/content/drive/MyDrive/DeepLearning/df_res_covid_tfidf_org_data.csv', index=False)"
      ],
      "id": "6acd905e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0764ab08"
      },
      "source": [
        "# Wikipedia"
      ],
      "id": "0764ab08"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9422de54"
      },
      "outputs": [],
      "source": [
        "## if not already downloaded\n",
        "# ds = load_dataset('wikipedia', \"20220301.simple\")\n",
        "## We take the training data and convert it to a Pandas DataFrame\n",
        "# df = ds.data['train'].to_pandas()"
      ],
      "id": "9422de54"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45cbece6"
      },
      "outputs": [],
      "source": [
        "## if not already downloaded\n",
        "ds = load_dataset('wikipedia', \"20220301.simple\")\n",
        "## We take the training data and convert it to a Pandas DataFrame\n",
        "df_wiki = ds.data['train'].to_pandas()\n",
        "df_wiki.head(3)"
      ],
      "id": "45cbece6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85460bf7"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "df_wiki['context_cleaned'] = df_wiki.text.apply(\n",
        "    lambda x: re.sub(r'https?:\\/\\/.*?[\\s+]|\\n|[^a-zA-z0-9.]', ' ', x)\n",
        ")"
      ],
      "id": "85460bf7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95c728ce"
      },
      "source": [
        "### Document Store"
      ],
      "id": "95c728ce"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kr4CB8b44UUn"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.2-linux-x86_64.tar.gz -q\n",
        "tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz\n",
        "chown -R daemon:daemon elasticsearch-7.9.2"
      ],
      "id": "Kr4CB8b44UUn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4jVprJ64UUq"
      },
      "outputs": [],
      "source": [
        "%%bash --bg\n",
        "\n",
        "sudo -u daemon -- elasticsearch-7.9.2/bin/elasticsearch"
      ],
      "id": "V4jVprJ64UUq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-70flpq4UUr"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "time.sleep(30)"
      ],
      "id": "L-70flpq4UUr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0140550"
      },
      "outputs": [],
      "source": [
        "documents_lst_wiki = df_wiki.to_dict(orient='records')"
      ],
      "id": "c0140550"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c277d2f7",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# the way document_store wants data formatted\n",
        "dicts_wiki = [\n",
        "    {\n",
        "        'content' : elm['text'],\n",
        "        'meta' : {\n",
        "            'name' : elm['title']\n",
        "        }\n",
        "    } \n",
        "    for elm in tqdm(documents_lst_wiki)\n",
        "]"
      ],
      "id": "c277d2f7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b101685a",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "document_store_wiki = ElasticsearchDocumentStore(\n",
        "    port=9200\n",
        ")\n",
        "document_store_wiki.delete_documents()\n",
        "document_store_wiki.write_documents(\n",
        "    documents=dicts_wiki\n",
        ")"
      ],
      "id": "b101685a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a4da1dc"
      },
      "source": [
        "### Retrieving answers"
      ],
      "id": "8a4da1dc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3cee012"
      },
      "source": [
        "#### BM25"
      ],
      "id": "f3cee012"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8bdaced"
      },
      "outputs": [],
      "source": [
        "retriever = BM25Retriever(document_store=document_store_wiki)\n",
        "\n",
        "reader = FARMReader(\n",
        "    model_name_or_path=model, #\"deepset/roberta-base-squad2\"\n",
        "    use_gpu=use_gpu\n",
        ")\n",
        "\n",
        "pipe_wiki = ExtractiveQAPipeline(reader, retriever)\n",
        "\n",
        "df_res_wiki_bm25 = qa_dataset.copy()\n",
        "\n",
        "# prepare columns for answers\n",
        "df_res_wiki_bm25['predictions_wiki_context_bm25'] = [list() for x in range(len(df_res_wiki_bm25.index))]\n",
        "\n",
        "for q_i in tqdm(range(len(qa_dataset.question.tolist()))):\n",
        "    \n",
        "    print('question : ', qa_dataset.question[q_i])\n",
        "    \n",
        "    try:\n",
        "        # covid dataset context prediction\n",
        "        prediction_wiki = pipe_wiki.run(\n",
        "            query=qa_dataset.question[q_i],\n",
        "            params={\n",
        "                \"Retriever\" : {\"top_k\": top_k_retriever},\n",
        "                \"Reader\": {\"top_k\": top_k_reader}\n",
        "            }\n",
        "        )\n",
        "\n",
        "        df_res_wiki_bm25.loc[q_i, 'predictions_wiki_context_bm25'].append(\n",
        "            [prediction_wiki['answers'][k].answer for k in range(len(prediction_wiki['answers']))]\n",
        "        )\n",
        "    except:\n",
        "        df_res_wiki_bm25.loc[q_i, 'predictions_wiki_context_bm25'].append([])\n",
        "\n",
        "df_res_wiki_bm25.to_csv('/content/drive/MyDrive/DeepLearning/df_res_wiki_bm25_org_data.csv', index=False)"
      ],
      "id": "a8bdaced"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r51SFx_5Rsp"
      },
      "source": [
        "#### RE-INITIALISE ELASTICSEARCH"
      ],
      "id": "6r51SFx_5Rsp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzmiEhVt76LR"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.2-linux-x86_64.tar.gz -q\n",
        "tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz\n",
        "chown -R daemon:daemon elasticsearch-7.9.2"
      ],
      "id": "nzmiEhVt76LR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cq2iZEjt76LT"
      },
      "outputs": [],
      "source": [
        "%%bash --bg\n",
        "\n",
        "sudo -u daemon -- elasticsearch-7.9.2/bin/elasticsearch"
      ],
      "id": "Cq2iZEjt76LT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_L-B1UR76LT"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "time.sleep(30)"
      ],
      "id": "y_L-B1UR76LT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ueb8ETi76LU"
      },
      "outputs": [],
      "source": [
        "documents_lst_wiki = df_wiki.to_dict(orient='records')"
      ],
      "id": "5ueb8ETi76LU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDLOfN3B76LV",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# the way document_store wants data formatted\n",
        "dicts_wiki = [\n",
        "    {\n",
        "        'content' : elm['text'],\n",
        "        'meta' : {\n",
        "            'name' : elm['title']\n",
        "        }\n",
        "    } \n",
        "    for elm in tqdm(documents_lst_wiki)\n",
        "]"
      ],
      "id": "eDLOfN3B76LV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8hU1JY776LX",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "document_store_wiki = ElasticsearchDocumentStore(\n",
        "    port=9200\n",
        ")\n",
        "document_store_wiki.delete_documents()\n",
        "document_store_wiki.write_documents(\n",
        "    documents=dicts_wiki\n",
        ")"
      ],
      "id": "g8hU1JY776LX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b58968a3"
      },
      "source": [
        "#### TF IDF"
      ],
      "id": "b58968a3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "371de3e6"
      },
      "outputs": [],
      "source": [
        "retriever = TfidfRetriever(document_store=document_store_wiki)\n",
        "\n",
        "reader = FARMReader(\n",
        "    model_name_or_path=model, #\"deepset/roberta-base-squad2\"\n",
        "    use_gpu=use_gpu\n",
        ")\n",
        "\n",
        "pipe_wiki = ExtractiveQAPipeline(reader, retriever)\n",
        "\n",
        "df_res_wiki_tfidf = qa_dataset.copy()\n",
        "\n",
        "# prepare columns for answers\n",
        "df_res_wiki_tfidf['predictions_wiki_context_tfidf'] = [list() for x in range(len(df_res_wiki_tfidf.index))]\n",
        "\n",
        "for q_i in tqdm(range(len(qa_dataset.question.tolist()))):\n",
        "    \n",
        "    print('question : ', qa_dataset.question[q_i])\n",
        "    \n",
        "    try:\n",
        "        # covid dataset context prediction\n",
        "        prediction_wiki = pipe_wiki.run(\n",
        "            query=qa_dataset.question[q_i],\n",
        "            params={\n",
        "                \"Retriever\" : {\"top_k\": top_k_retriever},\n",
        "                \"Reader\": {\"top_k\": top_k_reader}\n",
        "            }\n",
        "        )\n",
        "\n",
        "        df_res_wiki_tfidf.loc[q_i, 'predictions_wiki_context_tfidf'].append(\n",
        "            [prediction_wiki['answers'][k].answer for k in range(len(prediction_wiki['answers']))]\n",
        "        )\n",
        "    except:\n",
        "        df_res_wiki_tfidf.loc[q_i, 'predictions_wiki_context_tfidf'].append([])\n",
        "\n",
        "df_res_wiki_tfidf.to_csv('/content/drive/MyDrive/DeepLearning/df_res_wiki_tfidf_org_data.csv', index=False)"
      ],
      "id": "371de3e6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b918c5b"
      },
      "source": [
        "# Wikipedia API"
      ],
      "id": "2b918c5b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b36ea6d6"
      },
      "source": [
        "### Document store"
      ],
      "id": "b36ea6d6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ixsiOIc4SJA"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.2-linux-x86_64.tar.gz -q\n",
        "tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz\n",
        "chown -R daemon:daemon elasticsearch-7.9.2"
      ],
      "id": "2ixsiOIc4SJA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIvdQqfD4SJC"
      },
      "outputs": [],
      "source": [
        "%%bash --bg\n",
        "\n",
        "sudo -u daemon -- elasticsearch-7.9.2/bin/elasticsearch"
      ],
      "id": "BIvdQqfD4SJC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqfg2E7u4SJC"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "time.sleep(30)"
      ],
      "id": "bqfg2E7u4SJC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b417fb41"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from haystack.document_stores import ElasticsearchDocumentStore\n",
        "\n",
        "document_store_wikiAPI = ElasticsearchDocumentStore(\n",
        "    port=9200\n",
        ")\n",
        "document_store_wikiAPI.delete_documents()"
      ],
      "id": "b417fb41"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfc9e78d"
      },
      "source": [
        "### Retrieving answers"
      ],
      "id": "dfc9e78d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8a5bd37"
      },
      "source": [
        "#### BM25"
      ],
      "id": "a8a5bd37"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f82f36ec"
      },
      "outputs": [],
      "source": [
        "reader = FARMReader(\n",
        "    model_name_or_path=model, #\"deepset/roberta-base-squad2\"\n",
        "    use_gpu=use_gpu\n",
        ")\n",
        "\n",
        "df_res_wikiAPI_bm25 = qa_dataset.copy()\n",
        "\n",
        "# prepare columns for answers\n",
        "df_res_wikiAPI_bm25['predictions_wikiAPI_context_bm25'] = [list() for x in range(len(df_res_wikiAPI_bm25.index))]\n",
        "\n",
        "\n",
        "for q_i in tqdm(range(len(qa_dataset.question.tolist()))):\n",
        "    \n",
        "    print('question : ', qa_dataset.question[q_i])\n",
        "    \n",
        "    # wikipedia API context prediction \n",
        "    try:\n",
        "        search_results_wikiAPI = wiki.search(qa_dataset.question[q_i])\n",
        "\n",
        "        wiki_pages = [\n",
        "            wiki.page(res)\n",
        "            for res in search_results_wikiAPI[:top_k_reader]\n",
        "        ]\n",
        "        \n",
        "        dicts_wikiAPI = [\n",
        "            {\n",
        "                'content' : wiki_page.content,\n",
        "                'meta' : {\n",
        "                    'name' : wiki_page.title\n",
        "                }\n",
        "            } \n",
        "            for wiki_page in tqdm(wiki_pages)\n",
        "        ]\n",
        "        \n",
        "        \n",
        "        document_store_wikiAPI.delete_documents()\n",
        "        document_store_wikiAPI.write_documents(dicts_wikiAPI)\n",
        "        \n",
        "        retriever_wikiAPI = BM25Retriever(document_store=document_store_wikiAPI)\n",
        "        \n",
        "        pipe_wikiAPI = ExtractiveQAPipeline(reader, retriever_wikiAPI)\n",
        "        \n",
        "        prediction_wikiAPI = pipe_wikiAPI.run(\n",
        "            query=qa_dataset.question[q_i],\n",
        "            params={\n",
        "                \"Retriever\" : {\"top_k\": top_k_retriever},\n",
        "                \"Reader\": {\"top_k\": top_k_reader}\n",
        "            }\n",
        "        )\n",
        "\n",
        "        df_res_wikiAPI_bm25.loc[q_i, 'predictions_wikiAPI_context_bm25'].append(\n",
        "            [prediction_wikiAPI['answers'][k].answer for k in range(len(prediction_wikiAPI['answers']))]\n",
        "        )\n",
        "    except:\n",
        "        df_res_wikiAPI_bm25.loc[q_i, 'predictions_wikiAPI_context_bm25'].append([])\n",
        "\n",
        "df_res_wikiAPI_bm25.to_csv('/content/drive/MyDrive/DeepLearning/df_res_wikiAPI_bm25_org_data.csv', index=False)"
      ],
      "id": "f82f36ec"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLCCxjVI5iQ3"
      },
      "source": [
        "#### RE-INITIALISE ELASTICSEARCH"
      ],
      "id": "jLCCxjVI5iQ3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gq2wPgRg8FCp"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.2-linux-x86_64.tar.gz -q\n",
        "tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz\n",
        "chown -R daemon:daemon elasticsearch-7.9.2"
      ],
      "id": "Gq2wPgRg8FCp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12ZmrKWf8FCq"
      },
      "outputs": [],
      "source": [
        "%%bash --bg\n",
        "\n",
        "sudo -u daemon -- elasticsearch-7.9.2/bin/elasticsearch"
      ],
      "id": "12ZmrKWf8FCq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4DoZB9d8FCs"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "time.sleep(30)"
      ],
      "id": "n4DoZB9d8FCs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWaJPgQE8FCs"
      },
      "outputs": [],
      "source": [
        "document_store_wikiAPI = ElasticsearchDocumentStore(\n",
        "    port=9200\n",
        ")\n",
        "document_store_wikiAPI.delete_documents()"
      ],
      "id": "qWaJPgQE8FCs"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3feff8f5"
      },
      "source": [
        "#### TF IDF"
      ],
      "id": "3feff8f5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e633bb09"
      },
      "outputs": [],
      "source": [
        "reader = FARMReader(\n",
        "    model_name_or_path=model, #\"deepset/roberta-base-squad2\"\n",
        "    use_gpu=use_gpu\n",
        ")\n",
        "\n",
        "df_res_wikiAPI_tfidf = qa_dataset.copy()\n",
        "\n",
        "# prepare columns for answers\n",
        "df_res_wikiAPI_tfidf['predictions_wikiAPI_context_tfidf'] = [list() for x in range(len(df_res_wikiAPI_tfidf.index))]\n",
        "\n",
        "\n",
        "for q_i in tqdm(range(len(qa_dataset.question.tolist()))):\n",
        "    \n",
        "    print('question : ', qa_dataset.question[q_i])\n",
        "    \n",
        "    try:\n",
        "        # wikipedia API context prediction \n",
        "        search_results_wikiAPI = wiki.search(qa_dataset.question[q_i])\n",
        "\n",
        "        wiki_pages = [\n",
        "            wiki.page(res)\n",
        "            for res in search_results_wikiAPI[:top_k_reader]\n",
        "        ]\n",
        "        \n",
        "        dicts_wikiAPI = [\n",
        "            {\n",
        "                'content' : wiki_page.content,\n",
        "                'meta' : {\n",
        "                    'name' : wiki_page.title\n",
        "                }\n",
        "            } \n",
        "            for wiki_page in tqdm(wiki_pages)\n",
        "        ]\n",
        "        \n",
        "        \n",
        "        document_store_wikiAPI.delete_documents()\n",
        "        document_store_wikiAPI.write_documents(dicts_wikiAPI)\n",
        "        \n",
        "        retriever_wikiAPI = TfidfRetriever(document_store=document_store_wikiAPI)\n",
        "        \n",
        "        pipe_wikiAPI = ExtractiveQAPipeline(reader, retriever_wikiAPI)\n",
        "        \n",
        "        prediction_wikiAPI = pipe_wikiAPI.run(\n",
        "            query=qa_dataset.question[q_i],\n",
        "            params={\n",
        "                \"Retriever\" : {\"top_k\": top_k_retriever},\n",
        "                \"Reader\": {\"top_k\": top_k_reader}\n",
        "            }\n",
        "        )\n",
        "\n",
        "        df_res_wikiAPI_tfidf.loc[q_i, 'predictions_wikiAPI_context_tfidf'].append(\n",
        "            [prediction_wikiAPI['answers'][k].answer for k in range(len(prediction_wikiAPI['answers']))]\n",
        "        )\n",
        "    except:\n",
        "        df_res_wikiAPI_tfidf.loc[q_i, 'predictions_wikiAPI_context_tfidf'].append([])\n",
        "\n",
        "df_res_wikiAPI_tfidf.to_csv('/content/drive/MyDrive/DeepLearning/df_res_wikiAPI_tfidf_org_data.csv', index=False)"
      ],
      "id": "e633bb09"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3721474"
      },
      "source": [
        "# Combining dataframes "
      ],
      "id": "d3721474"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GXyPJcB3fPc"
      },
      "outputs": [],
      "source": [
        "df_res_covid_tfidf = pd.read_csv('/content/drive/MyDrive/DeepLearning/df_res_covid_tfidf_org_data.csv')\n",
        "df_res_covid_bm25 = pd.read_csv('/content/drive/MyDrive/DeepLearning/df_res_covid_bm25_org_data.csv')\n",
        "df_res_wiki_bm25 = pd.read_csv('/content/drive/MyDrive/DeepLearning/df_res_wiki_bm25_org_data.csv')\n",
        "df_res_wiki_tfidf = pd.read_csv('/content/drive/MyDrive/DeepLearning/df_res_wiki_tfidf_org_data.csv')\n",
        "df_res_wikiAPI_bm25 = pd.read_csv('/content/drive/MyDrive/DeepLearning/df_res_wikiAPI_bm25_org_data.csv')\n",
        "df_res_wikiAPI_tfidf = pd.read_csv('/content/drive/MyDrive/DeepLearning/df_res_wikiAPI_tfidf_org_data.csv')"
      ],
      "id": "1GXyPJcB3fPc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rg4FiqLa3pMH"
      },
      "outputs": [],
      "source": [
        "df_res = qa_dataset.copy()"
      ],
      "id": "Rg4FiqLa3pMH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46a38bb9"
      },
      "outputs": [],
      "source": [
        "df_res['predictions_covid_context_tfidf'] = df_res_covid_tfidf['predictions_covid_context_tfidf'].copy()\n",
        "df_res['predictions_covid_context_bm25'] = df_res_covid_bm25['predictions_covid_context_bm25'].copy()\n",
        "df_res['predictions_wiki_context_bm25'] = df_res_wiki_bm25['predictions_wiki_context_bm25'].copy()\n",
        "df_res['predictions_wiki_context_tfidf'] = df_res_wiki_tfidf['predictions_wiki_context_tfidf'].copy()\n",
        "df_res['predictions_wikiAPI_context_bm25'] = df_res_wikiAPI_bm25['predictions_wikiAPI_context_bm25'].copy()\n",
        "df_res['predictions_wikiAPI_context_tfidf'] = df_res_wikiAPI_tfidf['predictions_wikiAPI_context_tfidf'].copy()"
      ],
      "id": "46a38bb9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "la53JWi_43mn"
      },
      "source": [
        "### Save dataframe as csv to drive\n"
      ],
      "id": "la53JWi_43mn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c6ea308"
      },
      "outputs": [],
      "source": [
        "df_res.to_csv('/content/drive/MyDrive/DeepLearning/df_res_squad_coviddata_top5.csv', index=False)"
      ],
      "id": "5c6ea308"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.15"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "358.4px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}